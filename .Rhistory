colSums(is.na(spotify))
# Cek duplikasi
sum(duplicated(spotify))
str(spotify)
# cek data kotor
spotify %>%
filter(avg_daily_minutes < 0) %>%
head()
sum(spotify$avg_daily_minutes < 0, na.rm = TRUE)
# ganti data kotor dengan median
spotify <- spotify %>%
mutate(avg_daily_minutes = replace(avg_daily_minutes,
avg_daily_minutes < 0,
median(avg_daily_minutes[avg_daily_minutes >= 0], na.rm = TRUE)))
summary(spotify$avg_daily_minutes)
sum(spotify$avg_daily_minutes < 0)
str(spotify)
glimpse(spotify)
spotify <- spotify %>%
mutate(
subscription_type = as.factor(subscription_type),
country = as.factor(country),
top_genre = as.factor(top_genre),
churned = as.factor(churned)
)
str(spotify)
colSums(is.na(spotify))
# data latih 70 data tes 30
set.seed(123)
train_index <- createDataPartition(spotify$churned, p = 0.7, list = FALSE)
train_data <- spotify[train_index, ]
test_data  <- spotify[-train_index, ]
# Cek kelas sebelum SMOTE
cat("Kelas sebelum SMOTE:\n")
table(train_data$churned)
# Hapus user_id
train_no_id <- train_data %>% select(-user_id)
test_no_id  <- test_data %>% select(-user_id)
# Buat model encoding
dummies <- dummyVars(churned ~ ., data = train_no_id)
# Transform data menjadi numerik semua
train_x <- predict(dummies, newdata = train_no_id) %>% as.data.frame()
train_y <- train_no_id$churned
test_x  <- predict(dummies, newdata = test_no_id) %>% as.data.frame()
library(smotefamily)
smote_output <- SMOTE(
X = train_x,
target = train_y,
K = 5,
dup_size = 2
)
train_smote <- smote_output$data
train_smote$churned <- as.factor(smote_output$target)
# =====================================================
# LOAD LIBRARY
# =====================================================
library(tidyverse)
library(randomForest)
library(caret)
library(smotefamily)
# =====================================================
# LOAD DATA
# =====================================================
spotify <- read_csv("data/spotify_churn_dataset.csv", show_col_types = FALSE)
# Perbaiki data kotor
spotify <- spotify %>%
mutate(avg_daily_minutes = replace(avg_daily_minutes,
avg_daily_minutes < 0,
median(avg_daily_minutes[avg_daily_minutes >= 0], na.rm = TRUE)))
# Ubah factor
spotify <- spotify %>%
mutate(
subscription_type = as.factor(subscription_type),
country = as.factor(country),
top_genre = as.factor(top_genre),
churned = as.factor(churned)
)
# =====================================================
# SPLIT DATA (STRATIFIED)
# =====================================================
set.seed(123)
train_index <- createDataPartition(spotify$churned, p = 0.7, list = FALSE)
train_data <- spotify[train_index, ]
test_data  <- spotify[-train_index, ]
cat("Kelas sebelum SMOTE:\n")
print(table(train_data$churned))
# Hapus kolom user_id
train_no_id <- train_data %>% select(-user_id)
test_no_id  <- test_data  %>% select(-user_id)
# Encoding (dummy semua variabel non-numerik)
dummies <- dummyVars(churned ~ ., data = train_no_id)
train_x <- predict(dummies, newdata = train_no_id) %>% as.data.frame()
test_x  <- predict(dummies, newdata = test_no_id) %>% as.data.frame()
# Target harus numeric (0/1)
train_y <- as.numeric(as.character(train_no_id$churned))
# =====================================================
# SMOTE (smotefamily)
# =====================================================
smote_output <- SMOTE(
X = train_x,
target = train_y,
K = 5,
dup_size = 2
)
train_smote <- smote_output$data
train_smote$churned <- as.factor(smote_output$target)
cat("\nKelas setelah SMOTE:\n")
print(table(train_smote$churned))
# =====================================================
# RANDOM FOREST MODEL
# =====================================================
rf_model <- randomForest(
churned ~ .,
data = train_smote,
ntree = 500,
mtry = 3,
importance = TRUE
)
print(rf_model)
# =====================================================
# PREDIKSI
# =====================================================
pred <- predict(rf_model, test_x)
confusionMatrix(pred, test_data$churned, positive = "1")
# 1. Load Library
library(tidyverse)
library(randomForest)
library(caret)
library(smotefamily)
# 2. Load Dataset
spotify <- read_csv("spotify_churn_dataset (1).csv", show_col_types = FALSE)
# 1. Load Library
library(tidyverse)
library(randomForest)
library(caret)
library(smotefamily)
# 2. Load Dataset
spotify <- read_csv("data/spotify_churn_dataset.csv", show_col_types = FALSE)
# 3. Data Cleaning (Persis seperti kodemu)
# Ganti data kotor (negatif) dengan median
# Kita hitung median dari nilai positif saja
median_val <- median(spotify$avg_daily_minutes[spotify$avg_daily_minutes >= 0], na.rm = TRUE)
spotify <- spotify %>%
mutate(avg_daily_minutes = ifelse(avg_daily_minutes < 0, median_val, avg_daily_minutes))
# 4. Preprocessing Khusus untuk SMOTE
# Hapus user_id karena tidak berguna untuk prediksi
spotify_clean <- spotify %>%
select(-user_id)
# Pastikan Target (churned) adalah Factor untuk klasifikasi nanti,
# TAPI untuk SMOTE sementara kita butuh dia sebagai angka (0 dan 1) dulu
spotify_clean$churned <- as.factor(spotify_clean$churned)
# --- LANGKAH KUNCI: ONE-HOT ENCODING ---
# Kita ubah semua kolom kategori (country, genre, subscription) menjadi angka dummy
# Kita gunakan fungsi dummyVars dari caret
dummies_model <- dummyVars(churned ~ ., data = spotify_clean)
# Terapkan ke dataset (ini akan mengubah kategori jadi kolom angka, misal: country_US = 1)
data_numeric <- predict(dummies_model, newdata = spotify_clean)
data_numeric <- as.data.frame(data_numeric)
# Gabungkan kembali dengan target 'churned'
# Penting: SMOTE butuh target dalam bentuk numerik/integer (0/1) atau character saat proses,
# tapi agar aman kita tempelkan target asli
data_numeric$churned <- spotify_clean$churned
# Cek struktur baru (semua harus numeric/integer, kecuali churned boleh factor)
glimpse(data_numeric)
# 5. Split Data (Latih 70%, Tes 30%)
set.seed(123)
train_index <- createDataPartition(data_numeric$churned, p = 0.7, list = FALSE)
train_data <- data_numeric[train_index, ]
test_data  <- data_numeric[-train_index, ]
# Cek ketimpangan data sebelum SMOTE
cat("Jumlah kelas sebelum SMOTE:\n")
table(train_data$churned)
# 6. Penerapan SMOTE
# Siapkan X (fitur) dan Y (target)
# SMOTE butuh input X semuanya angka
train_x <- train_data %>% select(-churned)
train_y <- train_data$churned
# Jalankan SMOTE
# dup_size 0 artinya algoritma akan otomatis menyeimbangkan sampai jumlahnya setara
smote_output <- SMOTE(X = train_x, target = train_y, K = 5, dup_size = 0)
# Ambil data hasil SMOTE
train_smote <- smote_output$data
# Perbaikan nama kolom target
# smotefamily biasanya memberi nama kolom target terakhir sebagai "class", kita ubah balik ke "churned"
colnames(train_smote)[ncol(train_smote)] <- "churned"
# PENTING: Kembalikan 'churned' menjadi Factor agar Random Forest membacanya sebagai Klasifikasi (bukan Regresi)
train_smote$churned <- as.factor(train_smote$churned)
cat("\nJumlah kelas setelah SMOTE:\n")
table(train_smote$churned)
# 7. Pelatihan Model Random Forest
# Kita latih menggunakan data yang sudah di-SMOTE
rf_model <- randomForest(
churned ~ .,
data = train_smote,
ntree = 500,
mtry = 3,
importance = TRUE
)
library(tidyverse)
library(randomForest)
library(caret)
library(smotefamily)
# Load Dataset
spotify <- read_csv("spotify_churn_dataset (1).csv", show_col_types = FALSE)
# Ganti nilai negatif di avg_daily_minutes
median_val <- median(spotify$avg_daily_minutes[spotify$avg_daily_minutes >= 0], na.rm = TRUE)
spotify <- spotify %>% mutate(avg_daily_minutes = ifelse(avg_daily_minutes < 0, median_val, avg_daily_minutes))
# Buang user_id
spotify_clean <- spotify %>% select(-user_id)
# Jadikan target sebagai factor
spotify_clean$churned <- as.factor(spotify_clean$churned)
# ========== SPLIT DATA ==========
set.seed(123)
train_index <- createDataPartition(spotify_clean$churned, p = 0.7, list = FALSE)
library(tidyverse)
library(randomForest)
library(caret)
library(smotefamily)
# Load Dataset
spotify <- read_csv("data/spotify_churn_dataset.csv", show_col_types = FALSE)
# Ganti nilai negatif di avg_daily_minutes
median_val <- median(spotify$avg_daily_minutes[spotify$avg_daily_minutes >= 0], na.rm = TRUE)
spotify <- spotify %>% mutate(avg_daily_minutes = ifelse(avg_daily_minutes < 0, median_val, avg_daily_minutes))
# Buang user_id
spotify_clean <- spotify %>% select(-user_id)
# Jadikan target sebagai factor
spotify_clean$churned <- as.factor(spotify_clean$churned)
# ========== SPLIT DATA ==========
set.seed(123)
train_index <- createDataPartition(spotify_clean$churned, p = 0.7, list = FALSE)
train_data <- spotify_clean[train_index, ]
test_data  <- spotify_clean[-train_index, ]
# ========== ONE-HOT ENCODING (HARUS dari TRAIN) ==========
# Buat model dummy hanya dari train
dummies_model <- dummyVars(churned ~ ., data = train_data)
# Terapkan encoding ke train dan test
train_x <- predict(dummies_model, newdata = train_data) %>% as.data.frame()
test_x  <- predict(dummies_model, newdata = test_data) %>% as.data.frame()
# Tambahkan kembali target churn
train_x$churned <- train_data$churned
test_x$churned  <- test_data$churned
# ========== SMOTE ==========
train_y <- train_x$churned
train_x_no_target <- train_x %>% select(-churned)
smote_out <- SMOTE(
X = train_x_no_target,
target = train_y,
K = 5,
dup_size = 0
)
train_smote <- smote_out$data
colnames(train_smote)[ncol(train_smote)] <- "churned"
train_smote$churned <- as.factor(train_smote$churned)
cat("\nJumlah kelas setelah SMOTE:\n")
print(table(train_smote$churned))
# ========== Random Forest ==========
rf_model <- randomForest(
churned ~ .,
data = train_smote,
ntree = 500,
mtry = 3,
importance = TRUE
)
# 1. Load Library
library(tidyverse)
library(randomForest)
library(caret)
library(smotefamily)
# 2. Load Dataset
# Pastikan nama file sesuai lokasi Anda
spotify <- read_csv("data/spotify_churn_dataset.csv", show_col_types = FALSE)
# 3. Data Cleaning (Membersihkan nilai negatif)
median_val <- median(spotify$avg_daily_minutes[spotify$avg_daily_minutes >= 0], na.rm = TRUE)
spotify <- spotify %>%
mutate(avg_daily_minutes = ifelse(avg_daily_minutes < 0, median_val, avg_daily_minutes))
# 4. Preprocessing Khusus untuk SMOTE
# Hapus user_id
spotify_clean <- spotify %>%
select(-user_id)
# --- LANGKAH KUNCI: ONE-HOT ENCODING ---
# Ubah kategori jadi angka
dummies_model <- dummyVars(churned ~ ., data = spotify_clean)
data_numeric <- predict(dummies_model, newdata = spotify_clean)
data_numeric <- as.data.frame(data_numeric)
# --- PERBAIKAN ERROR "Hip-Hop" ---
# Gunakan make.names() untuk mengganti spasi atau tanda '-' dengan titik '.'
# Contoh: 'top_genreHip-Hop' akan berubah otomatis menjadi 'top_genreHip.Hop'
colnames(data_numeric) <- make.names(colnames(data_numeric))
# Gabungkan kembali target churned
# Kita tempelkan target asli (masih dalam bentuk angka 0/1 untuk SMOTE)
data_numeric$churned <- spotify_clean$churned
# 5. Split Data (Latih 70%, Tes 30%)
set.seed(123)
train_index <- createDataPartition(data_numeric$churned, p = 0.7, list = FALSE)
train_data <- data_numeric[train_index, ]
test_data  <- data_numeric[-train_index, ]
# 6. Penerapan SMOTE
# Siapkan X (fitur) dan Y (target)
train_x <- train_data %>% select(-churned)
train_y <- train_data$churned
# Jalankan SMOTE
smote_output <- SMOTE(X = train_x, target = train_y, K = 5, dup_size = 0)
# Ambil data hasil SMOTE
train_smote <- smote_output$data
# Rapikan nama kolom hasil SMOTE
# smotefamily menaruh target di kolom terakhir dengan nama "class", kita ubah jadi "churned"
colnames(train_smote)[ncol(train_smote)] <- "churned"
# Pastikan nama kolom di train_smote juga aman (biasanya sudah aman, tapi untuk jaga-jaga)
colnames(train_smote) <- make.names(colnames(train_smote))
# PENTING: Ubah 'churned' jadi FACTOR agar Random Forest melakukan KLASIFIKASI
train_smote$churned <- as.factor(train_smote$churned)
test_data$churned   <- as.factor(test_data$churned) # Data test juga harus factor
cat("Jumlah kelas setelah SMOTE:\n")
table(train_smote$churned)
# 7. Pelatihan Model Random Forest
rf_model <- randomForest(
churned ~ .,
data = train_smote,
ntree = 500,
mtry = 3,
importance = TRUE
)
print(rf_model)
# 8. Evaluasi Model
pred <- predict(rf_model, test_data)
# Tampilkan Confusion Matrix
confusionMatrix(pred, test_data$churned, positive = "1", mode = "Prec_Recall")
# 9. Cek Variable Importance
varImpPlot(rf_model, main = "Variable Importance Random Forest")
# 8. Evaluasi Model
pred <- predict(rf_model, test_data)
# Tampilkan Confusion Matrix
# PERBAIKAN: "Prec_Recall" diubah menjadi "prec_recall"
confusionMatrix(pred, test_data$churned, positive = "1", mode = "prec_recall")
# 9. Cek Variable Importance
varImpPlot(rf_model, main = "Variable Importance Random Forest")
library(ggplot2)
ggplot(spotify, aes(avg_daily_minutes)) +
geom_histogram(bins = 30, fill = "steelblue", alpha = 0.7) +
theme_minimal() +
labs(title = "Distribusi Rata-rata Menit Pemakaian Harian")
par(mfrow=c(1,2))
barplot(table(train_data$churned), main="Before SMOTE", col="red")
barplot(table(train_smote$churned), main="After SMOTE", col="green")
sum(spotify$avg_daily_minutes < 0, na.rm = TRUE)
# load library
library(tidyverse)
library(randomForest)
library(caret)
library(smotefamily)
library(ggplot2)
# load dataset
spotify <- read_csv("data/spotify_churn_dataset.csv", show_col_types = FALSE)
cat("6 Baris Data Pertama:\n")
print(head(spotify))
cat("\nStruktur Dataset Awal:\n")
glimpse(spotify)
cat("\nCek Data Hilang (NA):\n")
print(colSums(is.na(spotify)))
cat("\nCek Duplikasi:\n")
print(sum(duplicated(spotify)))
str(spotify)
# cek data kotor
spotify %>%
filter(avg_daily_minutes < 0) %>%
head()
sum(spotify$avg_daily_minutes < 0, na.rm = TRUE)
median_val <- median(spotify$avg_daily_minutes[spotify$avg_daily_minutes >= 0], na.rm = TRUE)
spotify <- spotify %>%
mutate(avg_daily_minutes = ifelse(avg_daily_minutes < 0, median_val, avg_daily_minutes))
cat("\nCek kembali nilai negatif setelah diisi median:\n")
print(sum(spotify$avg_daily_minutes < 0)) # Hasil harusnya 0
# 3.2 Hapus user_id dan Siapkan Target
# user_id tidak dipakai sebagai fitur (dibuang)
spotify_clean <- spotify %>%
select(-user_id)
# 3.3 ONE-HOT ENCODING (Wajib sebelum SMOTE)
# Mengubah kategori (country, genre) menjadi kolom angka (dummy variables)
dummies_model <- dummyVars(churned ~ ., data = spotify_clean)
data_numeric <- predict(dummies_model, newdata = spotify_clean)
data_numeric <- as.data.frame(data_numeric)
# PERBAIKAN ERROR "Hip-Hop": membuat nama kolom aman
colnames(data_numeric) <- make.names(colnames(data_numeric))
# Gabungkan kembali target churned (masih dalam bentuk angka 0/1 untuk SMOTE)
data_numeric$churned <- spotify_clean$churned
set.seed(123)
train_index <- createDataPartition(data_numeric$churned, p = 0.7, list = FALSE)
train_data <- data_numeric[train_index, ]
test_data  <- data_numeric[-train_index, ]
cat("\nJumlah kelas sebelum SMOTE:\n")
print(table(train_data$churned)) # Cek imbalance data
train_x <- train_data %>% select(-churned)
train_y <- train_data$churned
# Menggunakan dup_size = 0 untuk menyeimbangkan kelas secara penuh (dari Kode 2)
smote_output <- SMOTE(X = train_x, target = train_y, K = 5, dup_size = 0)
# Ambil data hasil SMOTE
train_smote <- smote_output$data
# Rapikan nama kolom hasil SMOTE
colnames(train_smote)[ncol(train_smote)] <- "churned"
colnames(train_smote) <- make.names(colnames(train_smote)) # Jaga-jaga
# PENTING: Ubah 'churned' jadi FACTOR agar Random Forest melakukan KLASIFIKASI
train_smote$churned <- as.factor(train_smote$churned)
test_data$churned   <- as.factor(test_data$churned) # Data test juga harus factor
cat("\nJumlah kelas setelah SMOTE:\n")
print(table(train_smote$churned)) # Cek data setelah balance
rf_model <- randomForest(
churned ~ .,
data = train_smote,
ntree = 500,
mtry = 3,
importance = TRUE
)
cat("\nHasil Model Random Forest:\n")
print(rf_model)
# Prediksi menggunakan test_data (yang sudah di-encoded)
pred <- predict(rf_model, test_data)
# Tampilkan Confusion Matrix
# Menggunakan mode = "prec_recall" (sudah diperbaiki case sensitivity-nya)
cat("\nHasil Evaluasi (Confusion Matrix & Metrik):")
confusionMatrix(pred, test_data$churned, positive = "1", mode = "prec_recall")
# Cek Variable Importance (Fitur yang paling berpengaruh)
varImpPlot(rf_model, main = "Variable Importance Random Forest")
# Menggunakan data 'spotify' awal (sebelum encoding)
p1 <- ggplot(spotify, aes(avg_daily_minutes)) +
geom_histogram(bins = 30, fill = "steelblue", alpha = 0.7) +
theme_minimal() +
labs(title = "Distribusi Rata-rata Menit Pemakaian Harian")
print(p1)
# Visualisasi 8.2: Perbandingan Kelas Sebelum dan Sesudah SMOTE
par(mfrow=c(1,2))
barplot(table(train_data$churned), main="Sebelum SMOTE (Imbalanced)", col="red", ylab="Jumlah User")
barplot(table(train_smote$churned), main="Setelah SMOTE (Balanced)", col="green", ylab="Jumlah User")
# Kembalikan layout plot ke default
par(mfrow=c(1,1))
visualize_rf_results <- function(rf_model, cm_object) {
# 1. VISUALISASI VARIABLE IMPORTANCE (Bar Chart)
# Ekstrak data importance (Mean Decrease Gini)
imp_data <- as.data.frame(importance(rf_model))
# Gunakan MeanDecreaseGini (metrik default untuk klasifikasi)
imp_data <- imp_data %>%
tibble::rownames_to_column(var = "Feature") %>%
rename(Importance = MeanDecreaseGini) %>%
arrange(desc(Importance))
p1 <- ggplot(imp_data, aes(x = reorder(Feature, Importance), y = Importance)) +
geom_bar(stat = "identity", fill = "#1DB954") + # Warna hijau Spotify
coord_flip() +
labs(title = "1. Faktor Utama Prediksi Churn (Importance Score)",
x = "Fitur",
y = "Pentingnya (Mean Decrease Gini)") +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5, face = "bold"),
axis.text.y = element_text(size = 10))
# 2. VISUALISASI CONFUSION MATRIX SEBAGAI HEATMAP
# Ekstrak matrix table dari objek confusionMatrix
cm_table <- as.table(cm_object)
cm_df <- as.data.frame(cm_table)
colnames(cm_df) <- c("Predicted", "Actual", "Count")
# Hitung metrik kunci untuk subtitle
accuracy_val <- round(cm_object$overall['Accuracy'], 3)
recall_val <- round(cm_object$byClass['Recall'], 3)
precision_val <- round(cm_object$byClass['Precision'], 3)
# Label untuk heatmap (mengganti 0/1 dengan istilah bisnis)
cm_df$Actual_Label <- factor(cm_df$Actual, levels = c("0", "1"),
labels = c("Setia (0)", "Churn (1)"))
cm_df$Predicted_Label <- factor(cm_df$Predicted, levels = c("0", "1"),
labels = c("Setia (0)", "Churn (1)"))
p2 <- ggplot(cm_df, aes(x = Actual_Label, y = Predicted_Label, fill = Count)) +
geom_tile(color = "white") +
scale_fill_gradient(low = "white", high = "#004D7A") + # Skema warna gelap
geom_text(aes(label = paste(Count, "\n(", round(Count/sum(cm_df$Count)*100, 1), "%)")),
vjust = 1, color = "black", size = 5) +
labs(
title = "2. Hasil Prediksi Model (Confusion Matrix Heatmap)",
subtitle = paste0("Accuracy: ", accuracy_val, " | Recall: ", recall_val,
" | Precision: ", precision_val),
x = "Aktual (Referensi)",
y = "Prediksi (Model)"
) +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5, face = "bold"),
legend.position = "none",
axis.title = element_text(size = 12),
axis.text = element_text(size = 10))
# Tampilkan plot secara terpisah
print(p1)
print(p2)
}
# 7. EVALUASI MODEL (REVISI)
pred <- predict(rf_model, test_data)
# Simpan hasil confusionMatrix ke variabel cm_result
cm_result <- confusionMatrix(pred, test_data$churned, positive = "1", mode = "prec_recall")
# Panggil fungsi visualisasi yang baru dibuat
visualize_rf_results(rf_model, cm_result)
# cek data kotor
spotify %>%
filter(avg_daily_minutes < 0) %>%
head()
sum(spotify$avg_daily_minutes < 0, na.rm = TRUE)
median_val <- median(spotify$avg_daily_minutes[spotify$avg_daily_minutes >= 0], na.rm = TRUE)
spotify <- spotify %>%
mutate(avg_daily_minutes = ifelse(avg_daily_minutes < 0, median_val, avg_daily_minutes))
cat("\nCek kembali nilai negatif setelah diisi median:\n")
print(sum(spotify$avg_daily_minutes < 0)) # Hasil harusnya 0
print(colSums(is.na(spotify)))
cat("\nCek Duplikasi:\n")
print(sum(duplicated(spotify)))
str(spotify)
# cek data kotor
spotify %>%
filter(avg_daily_minutes < 0) %>%
head()
sum(spotify$avg_daily_minutes < 0, na.rm = TRUE)
